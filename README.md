# README

This program will run modular Differential Evolution \[3\] on a Neural Network in order to solve the Switch2-v0, Checkers-v0, or Compressed Checkers-v0 environments by ma-gym \[2\]. The progress of the training will be monitored and logged by the IOH-profiler \[1\]. Compressed Checkers-v0 is a version of Checkers-v0 with a simplified observation, reducing the dimensionality of the input by almost a factor 2.


#### options and flags
This program can be excetuted by running the Main.py script. The following flags or arguments can be added when running this program:<br/>
> The ``--dir`` flag can be used to specify the prefered location for saving the logs generated by the IOH-profiler.<br/>
> The ``--policy`` flag can be used to specify a file from which to load the weights of all agents when playing a demo or making a video. The weights should be separated by spaces. Note that the first two entries will be ignored. This allows one to directly copy a line from the logs provided by IOH into a policy file, as IOH does first log the fitness evaluation a fitness before the weights. By default this <br/>
> The ``--demo`` flag can be used to bypass the training loop and play a demo of an agent instead.<br/>
> The ``--video`` flag can be used to bypass the training loop and record a video of an agent instead.<br/>
> The ``--method`` flag can be used to chose between optimizing using "ModDE" or "RandomSearch". For modDE, the methods "MDE", "modde", and "modDE" are also valid choices and for RandomSearch, the methods "RS", "RNG", and "random_search" are also valid.<br/>
> The ``--env`` flag can be used to specify the environment, choosing between "checkers", and "switch". The default setting for this parameter is "checkers".<br/>
> The ``--compression`` flag can be used to train on the Compressed Checkers environment; compressing the observations for this environment. This parameter only takes effect when the ``--env`` flag is set to "checkers".<br/>


The following flags can be used to modify the settings for the neural network architectures used:<br/>
> The ``--shape`` flag can be used to determine the shape of the network architectures used by the agents. To use this parameter follow up with the desired sizes of the layers of the network. By default, no hidden layers are used, but up to two hidden layers are supported. 
> The ``--lstm`` flag can be used to ensure that agents use an LSTM layer as a hidden layer. When using this flag the user must specify a shape containing both numbers. The first number of the shape will be used to determine the size of the first hidden layer and the LSTM, whilst the second number will be used to specify the size of the second hidden layer. By default the network will not use an LSTM.<br/>
> The ``--bias`` flag can be used to enable bias nodes in the networks used for agents. By default, these are not used.<br/>




The following flag can be used to modify the settings and hyperparameters for modular differential evolution (modDE):<br/>
> The ``--popsize`` flag can be used to specify the population size used for differential evolution. This number will be scaled by the dimensionality of the search space. By default, this parameter is set to 15.<br/>
> The ``--maxiter`` flag can be used to specify the maximum number of iterations the differential evolution is allowed to run. Note that this number will be scaled by the dimensionality of the search space, as well as by the value of the ``popsize`` flag. By default, this parameter is set to 1000.<br/>
> The ``--bounds`` flag can be used to specify the bounds of the search space for modDE. Only the absolute value of the bounds needs to be specified. This value will be used for both the upper and lower bounds of the search space.<br/>
> The ``--F`` flag can be used to set the value of the mutation factor F, for modDE. By default this parameter is set to 5. <br/>
> The ``--CR`` flag can be used to set the value of the crossover rate CR, for modDE. By default this parameter is set to 5. <br/>



#### Examples
To run the program on the Compressed Checkers environment for 1000 generation (or 1000 times popsize times dimensionality fitness evaluations), with a population size of 5 times the dimensionality of the problem, and save the data in the "/home/logs" folder, run the program as follows:<br/>
	``python Main.py --dir /home/logs --popsize 5 --maxiter 1000 --compression``<br/>

To run a demo in the Compressed Checkers environment based on the network weights saved in the file ``weights_cc.txt`` run the program as follows:<br/>
	``python Main.py --demo --policy weights_cc.txt --compression``<br/>

You can check out all available options and flags by using:<br/>
	``python Main.py --help``<br/>



#### Input
Not applicable

#### Output
IOH-Logs containing the scores over time as well as the networks that achived those scores

## References
\[1\] Carola Doerr, Hao Wang, Furong Ye, Sander van Rijn, and Thomas Bäck. Iohprofiler: A bench-marking and profiling tool for iterative optimization heuristics. arXiv e-prints:1810.05281, oct 2018.

\[2\] Anurag Koul. ma-gym: Collection of multi-agent environments based on openai gym. [https://github.com/koulanurag/ma-gym](https://github.com/koulanurag/ma-gym), 2019

\[3\] Diederick Vermetten, Fabio Caraffini, Anna Kononova, and Thomas Bäck. Modular differential evolution. Conference: GECCO ’23: Genetic and Evolutionary Computation Conference, pages 864–872, 07 2023.

